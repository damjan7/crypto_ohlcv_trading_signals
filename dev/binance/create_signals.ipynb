{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the OHLCV data from binance, create all the needed features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import os\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "# change to rel. paths\n",
    "TICKER_DATA_PATH = r\"C:\\Users\\Damja\\CODING_LOCAL\\trading\\data\\ticker_specific_data_BINANCE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "### TO-DO's\n",
    "- create checks for correct dates\n",
    "- test data quality\n",
    "- create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.read_csv(\"pairs.csv\")\n",
    "NUM_PAIRS_TO_LOAD = 100\n",
    "pairs = pairs.iloc[:NUM_PAIRS_TO_LOAD, 0].values\n",
    "pairs = [pair.replace(\"USD\", \"USDT\") for pair in pairs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'scan' uses lazy evaluation --> optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0aaf22ada280>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pairs' is not defined"
     ]
    }
   ],
   "source": [
    "pair = pairs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(f'{TICKER_DATA_PATH}/{pair.replace(\"/\", \"\")}.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.collect_schema().names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Creation\n",
    "- 30 mins momentum\n",
    "- change in volume\n",
    "- current vol / 24h avg volume (check for weekends?) --> maybe a flag; is weekend or is change to weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.with_columns['usd_volume_30m_delta'] = df['usd_volume'].diff()\n",
    "\n",
    "df['usd_volume_30m_delta'] = df['usd_volume'].diff()\n",
    "df['usd_volume_60m_delta'] = df['usd_volume'].diff(2)\n",
    "df['usd_volume_3hm_delta'] = df['usd_volume'].diff(6)\n",
    "\n",
    "df['return_30m'] = df['close'].diff()/df['close']*100\n",
    "df['return_60m'] = df['close'].diff(2)/df['close']*100\n",
    "df['return_3h'] = df['close'].diff(6)/df['close']*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the rolling 6h Low and High prices; It's difference is a good proxy of coin specific volatility within this timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['6h_low'] = df['low'].rolling(12).min()\n",
    "df['6h_high'] = df['high'].rolling(12).max()\n",
    "df['6h_high_minus_low'] = df['6h_high'] - df['6h_low']\n",
    "\n",
    "df['6h_close_volatility'] = df['close'].rolling(12).std()\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] > pd.to_datetime(\"2025-01-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Step\n",
    "\n",
    "What is the naive benchmark that we need to be better than when looking at just 1 pair?\n",
    "- Better than long term buy and hold?\n",
    "- better in terms of risk measures (max DD, sharpe,..)\n",
    "\n",
    "\n",
    "One idea is not to always be invested but only in lucrative phases. This would lend to using leverage in these phases. Such a strategy would need to be evealuated based on drawdown events and hit ratio of the strategy in general. Either lower hit ratio with high payout potential or high hit ratio with higher leverage --> high conviction trades only.\n",
    "The question is what models lend itself to such a strategy?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
